# 重要编码规范
1. **禁止使用emoji字符**：所有代码和输出都不能包含emoji字符，避免GBK编码错误
2. **必须激活虚拟环境**：每次测试和运行代码前都要先执行 `source venv/Scripts/activate`
3. **编码兼容性**：确保所有输出在Windows中文环境下正常显示

# 项目优化任务清单

## 项目背景
- 数据源：data文件夹中7000+项目URL待爬取
- 目标：优化数据处理和AI查询性能
- 核心脚本：project_scraper_enhanced.py（详细爬取）、scraper_v2.py（基础信息爬取）

## 任务进度跟踪

### ✅ 已完成任务
- [x] 分析现有数据结构并制定优化方案

### 📋 待执行任务

**任务1：创建字段清理和标准化工具函数** ✅
- 文件位置：创建utils/data_cleaner.py
- 内容：
  - 品牌名称标准化函数（从title提取"品牌名×"格式）
  - HTML标签清理工具（清理agency字段的&nbsp;、HTML标签）
  - 日期格式标准化函数（统一为YYYY-MM-DD格式）
  - 关键词提取函数（从description中AI提取营销类型关键词）
  - 数据质量检查工具
- 工作量：1-2小时
- 完成时间：2025-08-07

**任务2：修改project_scraper_enhanced.py数据提取优化** ✅
- 文件位置：project_scraper_enhanced.py
- 内容：
  - 集成任务1的清理工具函数
  - 修复brand字段提取逻辑
  - 清理agency字段
  - 删除冗余字段：scraper_config、详细的batch_info、scraped_at、image_count
  - 添加新字段：keywords、category、industry、campaign_type
  - 优化数据输出格式
- 依赖：任务1完成
- 工作量：3-4小时
- 完成时间：2025-08-07

**任务3：创建全局索引生成器** ✅
- 文件位置：创建index_generator.py
- 内容：
  - 扫描output/目录下所有batch文件
  - 生成global_search_index.json包含：
    - brand_index：品牌→项目映射
    - keyword_index：关键词→项目映射  
    - category_index：分类→项目映射
    - date_index：日期→项目映射
    - industry_index：行业→项目映射
    - campaign_type_index：营销类型→项目映射
  - 实现增量更新机制
  - 索引完整性检查
  - 集成到project_scraper_enhanced.py中自动更新
- 依赖：任务2完成
- 工作量：2-3小时
- 完成时间：2025-08-07

**任务4：修改统计逻辑基于实际爬取数据** ✅
- 文件位置：data_analyzer.py
- 内容：
  - 统计数据源从Excel改为output/目录
  - 品牌数量基于已爬取项目的去重brand字段
  - 项目数量基于实际成功爬取的项目数
  - 保持web_data.json基础统计格式不变
  - 新增ScrapedDataAnalyzer类优先分析已爬取数据
  - 保留Excel分析作为备用方案
- 依赖：任务2、3完成
- 工作量：1-2小时
- 完成时间：2025-08-07

**任务5：优化AI查询系统** ✅
- 文件位置：project_assistant.py
- 内容：
  - 实现4步查询流程：
    1. 查询预处理（意图分析、关键词提取）
    2. 基于global_search_index.json快速定位
    3. 按需加载相关项目详细数据（限制20个项目内）
    4. AI基于精准数据生成回答
  - 优化上下文管理，提升响应速度和准确性
  - 新增QueryProcessingResult和IndexSearchResult数据结构
  - 实现备用回答机制确保系统稳定性
  - 支持批次文件缓存，提升详情加载效率
- 依赖：任务3完成  
- 工作量：3-4小时
- 完成时间：2025-08-07

**任务6：文件名和结构标准化** ✅
- 内容：
  - projects_summary.json → projects_index.json
  - projects_batch_xxx → batch_xxx.json
  - batch_index.json → batch_metadata.json
  - 更新相关代码中的文件路径引用
- 依赖：任务2-5完成
- 工作量：1小时

**任务7：测试和验证** ✅
- 内容：
  - 测试不同查询类型（品牌分析、项目搜索、统计查询）
  - 验证查询准确性和响应速度
  - 性能基准测试
  - 调优参数
- 依赖：所有任务完成
- 工作量：2-3小时

**任务8：集成部署** ✅
- 内容：
  - 更新start_dashboard.py集成索引生成
  - 更新web_server.py API接口
  - 测试Web界面
  - 确保向后兼容性
- 依赖：任务7完成
- 工作量：1-2小时

## 关键改进点
1. 数据质量：修复brand、agency、category字段的提取问题
2. 查询性能：通过全局索引实现快速定位，避免加载所有数据
3. AI准确性：分层查询减少无关数据干扰，提升回答质量
4. 扩展性：支持7000+项目规模，查询性能不下降

## 技术要点
- 爬虫脚本：project_scraper_enhanced.py负责详细内容爬取
- 索引策略：brand、keyword、category、date四个维度
- AI优化：限制上下文为相关的10-20个项目，提升处理效率
- 数据统计：基于实际爬取成功的项目，而非Excel中的URL数量

## 执行规则
1. 每完成一项任务，立即在claude.md中标记为已完成
2. 完成任务后向用户确认，得到确认后再开始下一项任务
3. 严格按照任务依赖关系执行，不跳跃执行

# 新问题发现与优化任务清单

## 任务背景
在系统实际使用中发现了4个关键问题需要优化，这些问题影响了系统的数据准确性、功能完整性和用户体验。

## 📋 新待执行任务

**任务9：Excel数据整合与Master表创建** ✅
- 问题背景：当前爬虫从网页提取品牌信息不准确，Excel中已有准确的品牌、代理商信息
- 解决方案：整合data/下所有Excel文件，创建master_projects.csv作为统一数据源
- 技术方案：
  - 以URL中的项目ID为主键进行去重合并（如从https://www.digitaling.com/projects/342236.html提取342236）
  - 同一项目ID存在多个记录时，保留来源文件时间戳最新的记录
  - Master表字段：project_id, url, brand, agency, title, publish_date, last_updated
  - 简化数据结构，移除company_name和image_url减轻数据负担
- 内容：
  - 创建Excel整合器(excel_integrator.py)
  - 按文件时间戳排序加载所有Excel文件的"所有项目合并"sheet
  - 基于project_id去重，优先保留新文件数据
  - 生成master_projects.csv作为统一数据源
  - 数据质量检查和验证
- 优先级：🔥 高优先级（基础架构改进）
- 依赖：无
- 工作量：2-3小时
- 完成时间：2025-08-07

**任务10：爬虫批次执行修复** ✅  
- 问题背景：project_scraper_enhanced.py分批次后只执行第一批次，后续批次未正确执行
- 解决方案：重写批次管理器，支持断点续传和状态跟踪
- 内容：
  - 诊断现有批次执行问题的根本原因
  - 重构批次管理逻辑
  - 添加批次状态跟踪(pending/running/completed/failed)
  - 实现断点续传机制
  - 独立批次调度器确保连续执行
  - 批次执行日志和监控
- 优先级：🔥 高优先级
- 依赖：任务9完成
- 工作量：3-4小时  
- 完成时间：待定

**任务11：数据叠加策略优化** ✅
- 问题背景：新爬虫任务在原有数据基础上叠加，可能导致数据冗余和版本混乱
- 解决方案：一键式自动数据源分析和整合
- 技术实现：
  - 启动时自动检查data文件夹中的Excel文件
  - 智能判断是否需要重新整合数据源
  - 自动运行excel_integrator.py更新master_projects.csv
  - 爬取完成后自动生成AI兼容的JSON格式数据
  - 完整的数据质量报告和状态检查
- 核心特性：
  - 一键式操作：运行run_enhanced_scraper_v3.py即可完成全流程
  - 智能增量更新：只在数据源更新时重新整合
  - 自动格式转换：完成后自动生成projects_index.json和global_search_index.json
  - 数据质量保证：内置数据完整性检查和状态报告
- 优先级：✅ 已完成
- 依赖：任务9、10完成
- 工作量：2小时
- 完成时间：2025-08-07

**任务12：AI对话系统重构** ✅
- 问题背景：AI只能给出"找到5个相关项目..."等模板化回答，缺乏真正智能分析
- 解决方案：AI查询翻译器 - 自然语言转查询指令的智能系统
- 创新架构：
  ```
  用户问题 → AI理解分析 → 生成查询指令 → 本地执行 → 返回数据 → AI专业解读
  ```
- 核心实现：
  - **SmartAIAssistant**: 主要AI对话引擎
  - **SmartQueryExecutor**: 基于CSV的智能查询执行器
  - **ContentLengthManager**: 智能内容长度控制（最多4500字符）
  - **PromptManager**: 独立提示词模板管理系统
  - **简化数据架构**: 只需master_projects.csv + 详细内容按需加载
- 技术特性：
  - **智能分页**: 自动控制返回项目数量，大内容自动提示"还有X个项目可查看"
  - **查询指令标准**: JSON格式的结构化查询指令，支持复杂条件筛选
  - **独立提示词**: prompts/simple_prompts.json，方便随时调整AI行为
  - **按需加载**: 只有用户需要详细内容时才从batch文件加载
  - **成本优化**: 避免大量数据传输，大幅减少API token消耗
- 支持查询类型：
  - count: 统计数量 ("有多少个品牌？")
  - list_brands/list_agencies: 列出品牌/代理商
  - search: 项目搜索 ("华为的营销项目")
  - filter: 条件筛选 ("2024年的项目")
  - aggregate: 聚合分析 ("每个品牌的项目数")
- 优先级：✅ 已完成
- 依赖：任务9、11完成
- 工作量：4小时
- 完成时间：2025-08-07

## ⚠️ 重要执行规则

**在每个任务开始前必须：**
1. **详细讨论具体问题**：深入分析问题的根本原因和细节
2. **确认解决方案**：讨论技术方案、实现路径、可能遇到的问题
3. **用户确认后再开始**：确保方向正确，避免返工
4. **任务完成后标记**：在CLAUDE.md中标记完成并向用户确认

**任务执行顺序：**
- 任务9（Excel整合）→ 任务10（批次修复）→ 任务11（数据策略）→ 任务12（AI重构）
- 每个任务都需要用户确认后再进行下一个

## 预期成果
1. **数据准确性大幅提升**：基于Excel准确信息，避免网页提取错误
2. **爬虫执行完整性**：所有批次正确执行，无遗漏
3. **AI对话质量显著改善**：智能化回答，减少模板化回复  
4. **系统架构更加合理**：数据流清晰，维护成本降低
