"""
Gemini API å®¢æˆ·ç«¯
å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è§£æå’Œå›ç­”ç”Ÿæˆ
"""

import json
import re
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import google.generativeai as genai
from dataclasses import dataclass


@dataclass
class QueryIntent:
    """æŸ¥è¯¢æ„å›¾æ•°æ®ç»“æ„"""
    query_type: str  # search, compare, analyze, statistics
    entities: Dict[str, Any]  # æå–çš„å®ä½“ä¿¡æ¯
    filters: Dict[str, Any]  # æŸ¥è¯¢æ¡ä»¶
    confidence: float  # ç½®ä¿¡åº¦
    raw_query: str  # åŸå§‹æŸ¥è¯¢


class GeminiClient:
    """Gemini API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        
        Args:
            api_key: Gemini APIå¯†é’¥
        """
        # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å–APIå¯†é’¥
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        
        if not self.api_key:
            raise ValueError("éœ€è¦æä¾›Gemini APIå¯†é’¥ã€‚è¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")
        
        # é…ç½®Gemini
        genai.configure(api_key=self.api_key)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        print("âœ… Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    
    def analyze_query(self, user_query: str, context: str = "") -> QueryIntent:
        """
        åˆ†æç”¨æˆ·æŸ¥è¯¢æ„å›¾
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            QueryIntentå¯¹è±¡
        """
        # æ„å»ºåˆ†ææç¤ºè¯
        prompt = self._build_analysis_prompt(user_query, context)
        
        try:
            # è°ƒç”¨Gemini API
            response = self.model.generate_content(prompt)
            
            # è§£æå“åº”
            result = self._parse_analysis_result(response.text, user_query)
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
            
            # è¿”å›é»˜è®¤æ„å›¾
            return QueryIntent(
                query_type="search",
                entities={},
                filters={},
                confidence=0.5,
                raw_query=user_query
            )
    
    def generate_answer(self, query: str, search_results: List[Dict], 
                       query_info: Dict = None) -> str:
        """
        åŸºäºæœç´¢ç»“æœç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            search_results: æœç´¢ç»“æœ
            query_info: æŸ¥è¯¢ä¿¡æ¯
            
        Returns:
            è‡ªç„¶è¯­è¨€å›ç­”
        """
        # æ„å»ºå›ç­”æç¤ºè¯
        prompt = self._build_answer_prompt(query, search_results, query_info)
        
        try:
            # è°ƒç”¨Gemini API
            response = self.model.generate_content(prompt)
            
            # æ·»åŠ åˆ°å¯¹è¯å†å²
            self.conversation_history.append({
                "query": query,
                "response": response.text,
                "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "result_count": len(search_results)
            })
            
            return response.text
            
        except Exception as e:
            print(f"âš ï¸ å›ç­”ç”Ÿæˆå¤±è´¥: {e}")
            
            # è¿”å›é»˜è®¤å›ç­”
            if search_results:
                return f"æ‰¾åˆ°äº† {len(search_results)} ä¸ªç›¸å…³é¡¹ç›®ã€‚ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•æä¾›è¯¦ç»†åˆ†æï¼Œè¯·æŸ¥çœ‹å…·ä½“é¡¹ç›®ä¿¡æ¯ã€‚"
            else:
                return "å¾ˆæŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„é¡¹ç›®ä¿¡æ¯ã€‚è¯·å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯ã€‚"
    
    def _build_analysis_prompt(self, user_query: str, context: str = "") -> str:
        """æ„å»ºæŸ¥è¯¢åˆ†ææç¤ºè¯"""
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®æ•°æ®æŸ¥è¯¢åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–ç»“æœã€‚

ç”¨æˆ·æŸ¥è¯¢: "{user_query}"
ä¸Šä¸‹æ–‡: {context}

è¯·åˆ†æå¹¶è¿”å›ä»¥ä¸‹ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
{{
    "query_type": "æŸ¥è¯¢ç±»å‹ (search/compare/analyze/statistics)",
    "entities": {{
        "brand": "å“ç‰Œåç§°ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "agency": "ä»£ç†å•†åç§°ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "project_name": "é¡¹ç›®åç§°ï¼ˆå¦‚æœæåˆ°ï¼‰",
        "industry": "è¡Œä¸šï¼ˆå¦‚æœæåˆ°ï¼‰",
        "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
    }},
    "filters": {{
        "date_range": "æ—¶é—´èŒƒå›´ï¼ˆå¦‚æœæåˆ°ï¼Œæ ¼å¼ï¼šrecent/2023-01/2023-01~2023-12ï¼‰",
        "limit": "ç»“æœæ•°é‡é™åˆ¶ï¼ˆå¦‚æœæåˆ°ï¼Œæ•°å­—ï¼‰"
    }},
    "confidence": "ç½®ä¿¡åº¦ (0.0-1.0)"
}}

åˆ†æè§„åˆ™ï¼š
1. search: å¯»æ‰¾ç‰¹å®šé¡¹ç›®ã€å“ç‰Œæˆ–å…³é”®è¯
2. compare: å¯¹æ¯”ä¸¤ä¸ªæˆ–å¤šä¸ªé¡¹ç›®/å“ç‰Œ
3. analyze: æ·±åº¦åˆ†æé¡¹ç›®ç‰¹ç‚¹ã€è¶‹åŠ¿ç­‰
4. statistics: ç»Ÿè®¡åˆ†æï¼Œå¦‚æ•°é‡ã€æ’è¡Œç­‰

5. æå–æ‰€æœ‰å¯èƒ½çš„å®ä½“ï¼ˆå“ç‰Œã€ä»£ç†å•†ã€å…³é”®è¯ç­‰ï¼‰
6. è¯†åˆ«æ—¶é—´ç›¸å…³è¯æ±‡ï¼š"æœ€è¿‘"=recentï¼Œ"ä»Šå¹´"=2024ï¼Œ"å»å¹´"=2023ç­‰
7. æ•°å­—è¯æ±‡è½¬æ¢ï¼šä¸€ä¸ª=1ï¼Œå‡ ä¸ª=5ï¼Œå¾ˆå¤š=20ç­‰

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
        return prompt
    
    def _build_answer_prompt(self, query: str, search_results: List[Dict], 
                           query_info: Dict = None) -> str:
        """æ„å»ºå›ç­”ç”Ÿæˆæç¤ºè¯"""
        
        # é™åˆ¶æœç´¢ç»“æœæ•°é‡ä»¥é¿å…promptè¿‡é•¿
        limited_results = search_results[:10] if len(search_results) > 10 else search_results
        
        # æ„å»ºé¡¹ç›®ä¿¡æ¯æ‘˜è¦
        projects_summary = []
        for i, project in enumerate(limited_results, 1):
            summary = f"""
é¡¹ç›®{i}:
- æ ‡é¢˜: {project.get('title', 'æœªçŸ¥')}
- å“ç‰Œ: {project.get('brand', 'æœªçŸ¥')}
- ä»£ç†å•†: {project.get('agency', 'æœªçŸ¥')}
- å‘å¸ƒæ—¶é—´: {project.get('publish_date', 'æœªçŸ¥')}
- åˆ†ç±»: {project.get('category', 'æœªçŸ¥')}
- URL: {project.get('url', '')}
"""
            projects_summary.append(summary)
        
        projects_text = "\n".join(projects_summary)
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¥é”€é¡¹ç›®åˆ†æå¸ˆã€‚è¯·åŸºäºæœç´¢ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ç”¨æˆ·é—®é¢˜: "{query}"
æœç´¢ç»“æœæ•°é‡: {len(search_results)}
æŸ¥è¯¢ä¿¡æ¯: {json.dumps(query_info, ensure_ascii=False) if query_info else "æ— "}

é¡¹ç›®è¯¦æƒ…:
{projects_text}

å›ç­”è¦æ±‚ï¼š
1. ç”¨è‡ªç„¶ã€ä¸“ä¸šçš„ä¸­æ–‡å›ç­”
2. æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´å›ç­”é£æ ¼ï¼š
   - æœç´¢ç±»: åˆ—å‡ºç›¸å…³é¡¹ç›®ï¼Œçªå‡ºå…³é”®ä¿¡æ¯
   - å¯¹æ¯”ç±»: å¯¹æ¯”åˆ†æé¡¹ç›®ç‰¹ç‚¹å’Œå·®å¼‚
   - åˆ†æç±»: æ·±å…¥åˆ†æè¶‹åŠ¿ã€ç‰¹ç‚¹ã€æ´å¯Ÿ
   - ç»Ÿè®¡ç±»: æä¾›æ•°æ®ç»Ÿè®¡å’Œæ’å
3. å¦‚æœç»“æœå¾ˆå¤šï¼Œé‡ç‚¹ä»‹ç»å‰å‡ ä¸ªï¼Œå¹¶è¯´æ˜æ€»æ•°
4. å¦‚æœæ²¡æœ‰ç»“æœï¼Œæä¾›æœç´¢å»ºè®®
5. é€‚å½“å¼•ç”¨å…·ä½“é¡¹ç›®ä¿¡æ¯æ”¯æ’‘è§‚ç‚¹
6. ä¿æŒå›ç­”ç®€æ´ä½†ä¿¡æ¯ä¸°å¯Œ

è¯·å¼€å§‹å›ç­”ï¼š
"""
        return prompt
    
    def _parse_analysis_result(self, response_text: str, user_query: str) -> QueryIntent:
        """è§£æGeminiçš„åˆ†æç»“æœ"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if not json_match:
                raise ValueError("æ— æ³•æ‰¾åˆ°JSONæ ¼å¼çš„å›ç­”")
            
            json_str = json_match.group(0)
            result = json.loads(json_str)
            
            return QueryIntent(
                query_type=result.get('query_type', 'search'),
                entities=result.get('entities', {}),
                filters=result.get('filters', {}),
                confidence=float(result.get('confidence', 0.5)),
                raw_query=user_query
            )
            
        except Exception as e:
            print(f"âš ï¸ è§£æåˆ†æç»“æœå¤±è´¥: {e}")
            print(f"åŸå§‹å›ç­”: {response_text}")
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…ä½œä¸ºå¤‡é€‰
            return self._fallback_analysis(user_query)
    
    def _fallback_analysis(self, user_query: str) -> QueryIntent:
        """å¤‡é€‰çš„æŸ¥è¯¢åˆ†ææ–¹æ³•ï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰"""
        query_lower = user_query.lower()
        
        # æŸ¥è¯¢ç±»å‹åˆ¤æ–­
        if any(word in query_lower for word in ['å¯¹æ¯”', 'æ¯”è¾ƒ', 'vs', 'å’Œ', 'ä¸']):
            query_type = 'compare'
        elif any(word in query_lower for word in ['ç»Ÿè®¡', 'æ•°é‡', 'æ’è¡Œ', 'å¤šå°‘', 'å‡ ä¸ª']):
            query_type = 'statistics'
        elif any(word in query_lower for word in ['åˆ†æ', 'è¶‹åŠ¿', 'ç‰¹ç‚¹', 'æ€ä¹ˆæ ·']):
            query_type = 'analyze'
        else:
            query_type = 'search'
        
        # ç®€å•çš„å®ä½“æå–
        entities = {}
        keywords = []
        
        # å“ç‰Œå…³é”®è¯
        brand_keywords = re.findall(r'å“ç‰Œ[\sï¼š:]*([^ï¼Œ,ã€‚.ï¼!ï¼Ÿ?]*)', query_lower)
        if brand_keywords:
            entities['brand'] = brand_keywords[0].strip()
        
        # ä»£ç†å•†å…³é”®è¯
        agency_keywords = re.findall(r'ä»£ç†å•†[\sï¼š:]*([^ï¼Œ,ã€‚.ï¼!ï¼Ÿ?]*)', query_lower)
        if agency_keywords:
            entities['agency'] = agency_keywords[0].strip()
        
        # é€šç”¨å…³é”®è¯æå–
        for word in query_lower.split():
            if len(word) > 1 and word not in ['çš„', 'äº†', 'åœ¨', 'æœ‰', 'æ˜¯', 'å’Œ', 'ä¸']:
                keywords.append(word)
        
        entities['keywords'] = keywords[:5]  # é™åˆ¶å…³é”®è¯æ•°é‡
        
        # æ—¶é—´è¿‡æ»¤
        filters = {}
        if any(word in query_lower for word in ['æœ€è¿‘', 'è¿‘æœŸ']):
            filters['date_range'] = 'recent'
        elif 'ä»Šå¹´' in query_lower:
            filters['date_range'] = '2024'
        elif 'å»å¹´' in query_lower:
            filters['date_range'] = '2023'
        
        return QueryIntent(
            query_type=query_type,
            entities=entities,
            filters=filters,
            confidence=0.6,
            raw_query=user_query
        )
    
    def get_conversation_history(self, limit: int = 10) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history[-limit:] if limit else self.conversation_history
    
    def clear_conversation_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        print("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
    
    def test_connection(self) -> bool:
        """æµ‹è¯•Gemini APIè¿æ¥"""
        try:
            response = self.model.generate_content("ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'")
            return "è¿æ¥" in response.text or "æˆåŠŸ" in response.text
        except Exception as e:
            print(f"âŒ Gemini APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•Geminiå®¢æˆ·ç«¯...")
    
    # æ³¨æ„ï¼šéœ€è¦è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡
    try:
        client = GeminiClient()
        
        # æµ‹è¯•è¿æ¥
        if client.test_connection():
            print("âœ… APIè¿æ¥æµ‹è¯•é€šè¿‡")
        else:
            print("âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥")
            exit(1)
        
        # æµ‹è¯•æŸ¥è¯¢åˆ†æ
        test_queries = [
            "å¸®æˆ‘æ‰¾ä¸€äº›å¯å£å¯ä¹çš„è¥é”€é¡¹ç›®",
            "æœ€è¿‘æœ‰å“ªäº›åˆ›æ„å¹¿å‘Šï¼Ÿ",
            "å¯¹æ¯”ä¸€ä¸‹å®é©¬å’Œå¥”é©°çš„è¥é”€ç­–ç•¥",
            "ç»Ÿè®¡ä¸€ä¸‹å„ä¸ªå“ç‰Œçš„é¡¹ç›®æ•°é‡"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
            intent = client.analyze_query(query)
            print(f"æŸ¥è¯¢ç±»å‹: {intent.query_type}")
            print(f"å®ä½“: {intent.entities}")
            print(f"è¿‡æ»¤æ¡ä»¶: {intent.filters}")
            print(f"ç½®ä¿¡åº¦: {intent.confidence}")
        
        print("\nâœ… Geminiå®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ")
        
    except ValueError as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥APIå¯†é’¥")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")