"""
é¡¹ç›®æ™ºèƒ½åŠ©æ‰‹
æ•´åˆæ•°æ®ç®¡ç†å’ŒGemini APIï¼Œæä¾›æ™ºèƒ½é—®ç­”æœåŠ¡
"""

import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict

from project_data_manager import ProjectDataManager, SearchResult
from gemini_client import GeminiClient, QueryIntent


@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡æ•°æ®ç»“æ„"""
    query: str
    intent: QueryIntent
    search_result: SearchResult
    answer: str
    timestamp: str
    processing_time: float


class ProjectAssistant:
    """é¡¹ç›®æ™ºèƒ½åŠ©æ‰‹"""
    
    def __init__(self, 
                 data_path: str = "output/projects_summary.json",
                 gemini_api_key: str = None):
        """
        åˆå§‹åŒ–æ™ºèƒ½åŠ©æ‰‹
        
        Args:
            data_path: é¡¹ç›®æ•°æ®æ–‡ä»¶è·¯å¾„
            gemini_api_key: Gemini APIå¯†é’¥
        """
        print("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–é¡¹ç›®æ™ºèƒ½åŠ©æ‰‹...")
        
        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        self.data_manager = ProjectDataManager(data_path)
        
        # å¦‚æœæ²¡æœ‰ä¼ å…¥API Keyï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶è·å–
        if not gemini_api_key:
            try:
                from config_loader import get_config
                config = get_config()
                gemini_api_key = config.get('GEMINI_API_KEY')
                print("ğŸ“¡ ä»é…ç½®æ–‡ä»¶åŠ è½½Gemini APIå¯†é’¥")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•ä»é…ç½®æ–‡ä»¶è·å–APIå¯†é’¥: {e}")
        
        # åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        self.gemini_client = GeminiClient(gemini_api_key)
        
        # å¯¹è¯å†å²
        self.conversation_history: List[ConversationTurn] = []
        
        # ç³»ç»ŸçŠ¶æ€
        self.ready = True
        
        print("âœ… é¡¹ç›®æ™ºèƒ½åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š å·²åŠ è½½ {len(self.data_manager.projects)} ä¸ªé¡¹ç›®")
    
    def ask(self, query: str) -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›å›ç­”
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            æ™ºèƒ½å›ç­”
        """
        start_time = datetime.now()
        
        try:
            print(f"ğŸ” å¤„ç†æŸ¥è¯¢: '{query}'")
            
            # 1. åˆ†ææŸ¥è¯¢æ„å›¾
            print("  1ï¸âƒ£ åˆ†ææŸ¥è¯¢æ„å›¾...")
            context = self._build_context()
            intent = self.gemini_client.analyze_query(query, context)
            print(f"     æŸ¥è¯¢ç±»å‹: {intent.query_type}")
            print(f"     ç½®ä¿¡åº¦: {intent.confidence:.2f}")
            
            # 2. æ‰§è¡Œæ•°æ®æœç´¢
            print("  2ï¸âƒ£ æ‰§è¡Œæ•°æ®æœç´¢...")
            search_result = self._execute_search(intent)
            print(f"     æ‰¾åˆ° {search_result.total_count} ä¸ªç›¸å…³é¡¹ç›®")
            
            # 3. ç”Ÿæˆæ™ºèƒ½å›ç­”
            print("  3ï¸âƒ£ ç”Ÿæˆæ™ºèƒ½å›ç­”...")
            answer = self._generate_answer(query, intent, search_result)
            
            # 4. è®°å½•å¯¹è¯
            processing_time = (datetime.now() - start_time).total_seconds()
            conversation_turn = ConversationTurn(
                query=query,
                intent=intent,
                search_result=search_result,
                answer=answer,
                timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                processing_time=processing_time
            )
            
            self.conversation_history.append(conversation_turn)
            
            print(f"âœ… æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œè€—æ—¶ {processing_time:.2f}ç§’")
            
            return answer
            
        except Exception as e:
            error_msg = f"å¾ˆæŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶å‡ºç°äº†é—®é¢˜: {str(e)}"
            print(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
            return error_msg
    
    def _build_context(self) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        if not self.conversation_history:
            return "è¿™æ˜¯å¯¹è¯çš„å¼€å§‹ã€‚"
        
        # å–æœ€è¿‘3è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
        recent_turns = self.conversation_history[-3:]
        context_parts = []
        
        for i, turn in enumerate(recent_turns, 1):
            context_parts.append(f"å‰{len(recent_turns)-i+1}è½®:")
            context_parts.append(f"  ç”¨æˆ·é—®: {turn.query}")
            context_parts.append(f"  æŸ¥è¯¢ç±»å‹: {turn.intent.query_type}")
            context_parts.append(f"  ç»“æœæ•°: {turn.search_result.total_count}")
        
        return "\n".join(context_parts)
    
    def _execute_search(self, intent: QueryIntent) -> SearchResult:
        """æ ¹æ®æŸ¥è¯¢æ„å›¾æ‰§è¡Œæœç´¢"""
        
        # æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©æœç´¢ç­–ç•¥
        if intent.query_type == "statistics":
            return self._handle_statistics_query(intent)
        elif intent.query_type == "compare":
            return self._handle_compare_query(intent)
        else:
            return self._handle_search_query(intent)
    
    def _handle_search_query(self, intent: QueryIntent) -> SearchResult:
        """å¤„ç†æœç´¢ç±»æŸ¥è¯¢"""
        # æå–æœç´¢å‚æ•°
        brand = intent.entities.get('brand')
        agency = intent.entities.get('agency')
        keywords = intent.entities.get('keywords', [])
        
        # å¤„ç†å…³é”®è¯
        keyword = None
        if keywords:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå…³é”®è¯ï¼Œæˆ–è€…åˆå¹¶å¤šä¸ªå…³é”®è¯
            keyword = ' '.join(keywords) if len(keywords) > 1 else keywords[0]
        
        # å¤„ç†æ—¶é—´èŒƒå›´
        start_date = None
        end_date = None
        date_range = intent.filters.get('date_range')
        
        if date_range == 'recent':
            # æœ€è¿‘30å¤©
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        elif date_range and date_range.isdigit():
            # ç‰¹å®šå¹´ä»½
            year = date_range
            start_date = f"{year}-01-01"
            end_date = f"{year}-12-31"
        elif date_range and '~' in date_range:
            # æ—¥æœŸèŒƒå›´
            try:
                start_date, end_date = date_range.split('~')
            except:
                pass
        
        # å¤„ç†æ•°é‡é™åˆ¶
        limit = intent.filters.get('limit', 20)  # é»˜è®¤é™åˆ¶20ä¸ªç»“æœ
        if isinstance(limit, str) and limit.isdigit():
            limit = int(limit)
        elif not isinstance(limit, int):
            limit = 20
        
        # æ‰§è¡Œé«˜çº§æœç´¢
        return self.data_manager.advanced_search(
            brand=brand,
            agency=agency,
            keyword=keyword,
            start_date=start_date,
            end_date=end_date,
            limit=limit
        )
    
    def _handle_statistics_query(self, intent: QueryIntent) -> SearchResult:
        """å¤„ç†ç»Ÿè®¡ç±»æŸ¥è¯¢"""
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.data_manager.get_statistics()
        
        # æ„å»ºç»Ÿè®¡ç»“æœ
        # è¿™é‡Œåˆ›å»ºä¸€ä¸ªç‰¹æ®Šçš„SearchResultæ¥æ‰¿è½½ç»Ÿè®¡ä¿¡æ¯
        return SearchResult(
            projects=[],  # ç»Ÿè®¡æŸ¥è¯¢ä¸è¿”å›å…·ä½“é¡¹ç›®
            total_count=0,
            query_info={
                "type": "statistics",
                "stats": stats,
                "intent": asdict(intent)
            },
            search_time=0.0
        )
    
    def _handle_compare_query(self, intent: QueryIntent) -> SearchResult:
        """å¤„ç†å¯¹æ¯”ç±»æŸ¥è¯¢"""
        keywords = intent.entities.get('keywords', [])
        
        if len(keywords) >= 2:
            # å¯¹æ¯”ä¸¤ä¸ªå…³é”®è¯ç›¸å…³çš„é¡¹ç›®
            results1 = self.data_manager.search_by_keyword(keywords[0])
            results2 = self.data_manager.search_by_keyword(keywords[1])
            
            # åˆå¹¶ç»“æœ
            combined_results = results1 + results2
            
            return SearchResult(
                projects=combined_results[:20],  # é™åˆ¶ç»“æœæ•°é‡
                total_count=len(combined_results),
                query_info={
                    "type": "compare",
                    "keywords": keywords,
                    "results1_count": len(results1),
                    "results2_count": len(results2),
                    "intent": asdict(intent)
                },
                search_time=0.0
            )
        else:
            # å›é€€åˆ°æ™®é€šæœç´¢
            return self._handle_search_query(intent)
    
    def _generate_answer(self, query: str, intent: QueryIntent, search_result: SearchResult) -> str:
        """ç”Ÿæˆæ™ºèƒ½å›ç­”"""
        
        # ç‰¹æ®Šå¤„ç†ç»Ÿè®¡ç±»æŸ¥è¯¢
        if intent.query_type == "statistics" and search_result.query_info.get("type") == "statistics":
            return self._generate_statistics_answer(query, search_result.query_info["stats"])
        
        # ä½¿ç”¨Geminiç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”
        answer = self.gemini_client.generate_answer(
            query=query,
            search_results=search_result.projects,
            query_info=search_result.query_info
        )
        
        # æ·»åŠ æœç´¢ä¿¡æ¯æ‘˜è¦
        if search_result.total_count > 0:
            summary = f"\n\nğŸ“Š æœç´¢æ‘˜è¦: æ‰¾åˆ° {search_result.total_count} ä¸ªç›¸å…³é¡¹ç›®ï¼Œè€—æ—¶ {search_result.search_time:.3f}ç§’"
            if search_result.total_count > 10:
                summary += f"ï¼ˆæ˜¾ç¤ºå‰10ä¸ªï¼‰"
            answer += summary
        
        return answer
    
    def _generate_statistics_answer(self, query: str, stats: Dict) -> str:
        """ç”Ÿæˆç»Ÿè®¡ç±»å›ç­”"""
        answer_parts = []
        
        # åŸºæœ¬ç»Ÿè®¡
        answer_parts.append(f"ğŸ“Š **é¡¹ç›®æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ**")
        answer_parts.append(f"â€¢ æ€»é¡¹ç›®æ•°: **{stats['total_projects']}** ä¸ª")
        answer_parts.append(f"â€¢ æ¶‰åŠå“ç‰Œ: **{stats['total_brands']}** ä¸ª")
        answer_parts.append(f"â€¢ åˆä½œä»£ç†å•†: **{stats['total_agencies']}** ä¸ª")
        
        # æ—¥æœŸèŒƒå›´
        if stats['date_range']['earliest'] and stats['date_range']['latest']:
            answer_parts.append(f"â€¢ æ—¶é—´è·¨åº¦: {stats['date_range']['earliest']} è‡³ {stats['date_range']['latest']}")
        
        # çƒ­é—¨å“ç‰Œ
        if stats['top_brands']:
            answer_parts.append(f"\nğŸ† **é¡¹ç›®æ•°é‡æœ€å¤šçš„å“ç‰Œ TOP5:**")
            for i, (brand, count) in enumerate(stats['top_brands'][:5], 1):
                answer_parts.append(f"{i}. {brand}: {count} ä¸ªé¡¹ç›®")
        
        # çƒ­é—¨ä»£ç†å•†
        if stats['top_agencies']:
            answer_parts.append(f"\nğŸ¢ **é¡¹ç›®æ•°é‡æœ€å¤šçš„ä»£ç†å•† TOP5:**")
            for i, (agency, count) in enumerate(stats['top_agencies'][:5], 1):
                answer_parts.append(f"{i}. {agency}: {count} ä¸ªé¡¹ç›®")
        
        # æœˆåº¦åˆ†å¸ƒï¼ˆæ˜¾ç¤ºæœ€è¿‘6ä¸ªæœˆï¼‰
        if stats['monthly_distribution']:
            answer_parts.append(f"\nğŸ“… **æœ€è¿‘æœˆä»½é¡¹ç›®åˆ†å¸ƒ:**")
            sorted_months = sorted(stats['monthly_distribution'].items(), reverse=True)[:6]
            for month, count in sorted_months:
                answer_parts.append(f"â€¢ {month}: {count} ä¸ªé¡¹ç›®")
        
        answer_parts.append(f"\nğŸ“ˆ æœ€åæ›´æ–°æ—¶é—´: {stats['last_updated']}")
        
        return "\n".join(answer_parts)
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        if not self.conversation_history:
            return {"message": "è¿˜æ²¡æœ‰å¯¹è¯è®°å½•"}
        
        total_turns = len(self.conversation_history)
        total_projects_found = sum(turn.search_result.total_count for turn in self.conversation_history)
        avg_processing_time = sum(turn.processing_time for turn in self.conversation_history) / total_turns
        
        query_types = [turn.intent.query_type for turn in self.conversation_history]
        query_type_counts = {}
        for qt in query_types:
            query_type_counts[qt] = query_type_counts.get(qt, 0) + 1
        
        return {
            "total_turns": total_turns,
            "total_projects_found": total_projects_found,
            "avg_processing_time": round(avg_processing_time, 2),
            "query_type_distribution": query_type_counts,
            "first_query_time": self.conversation_history[0].timestamp,
            "last_query_time": self.conversation_history[-1].timestamp,
        }
    
    def export_conversation(self, filename: str = None) -> str:
        """å¯¼å‡ºå¯¹è¯è®°å½•"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"conversation_export_{timestamp}.json"
        
        export_data = {
            "export_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "summary": self.get_conversation_summary(),
            "conversations": [asdict(turn) for turn in self.conversation_history]
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å¯¹è¯è®°å½•å·²å¯¼å‡ºåˆ°: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¯¹è¯è®°å½•å¤±è´¥: {e}")
            return ""
    
    def clear_conversation(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        self.gemini_client.clear_conversation_history()
        print("âœ… å¯¹è¯å†å²å·²æ¸…ç©º")
    
    def refresh_data(self) -> bool:
        """åˆ·æ–°é¡¹ç›®æ•°æ®"""
        return self.data_manager.refresh_data()
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        data_stats = self.data_manager.get_statistics()
        
        return {
            "ready": self.ready,
            "data_manager": {
                "projects_count": len(self.data_manager.projects),
                "last_updated": data_stats['last_updated'],
                "brands_count": data_stats['total_brands'],
                "agencies_count": data_stats['total_agencies']
            },
            "gemini_client": {
                "api_available": True,  # å‡è®¾å¯ç”¨ï¼Œå®é™…ä½¿ç”¨æ—¶å¯ä»¥æµ‹è¯•
                "conversation_turns": len(self.gemini_client.conversation_history)
            },
            "conversation": {
                "total_turns": len(self.conversation_history),
                "summary": self.get_conversation_summary() if self.conversation_history else None
            }
        }


if __name__ == "__main__":
    # æµ‹è¯•æ™ºèƒ½åŠ©æ‰‹
    print("ğŸ§ª æµ‹è¯•é¡¹ç›®æ™ºèƒ½åŠ©æ‰‹...")
    
    try:
        # åˆå§‹åŒ–åŠ©æ‰‹ï¼ˆéœ€è¦è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡ï¼‰
        assistant = ProjectAssistant()
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        status = assistant.get_system_status()
        print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: {json.dumps(status, ensure_ascii=False, indent=2)}")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "æœ‰å¤šå°‘ä¸ªé¡¹ç›®ï¼Ÿ",
            "æœ€è¿‘æœ‰å“ªäº›è¥é”€é¡¹ç›®ï¼Ÿ",
            "æ‰¾ä¸€äº›å…³äºæ±½è½¦å“ç‰Œçš„åˆ›æ„æ¡ˆä¾‹",
        ]
        
        for query in test_queries:
            print(f"\nğŸ¤– ç”¨æˆ·: {query}")
            answer = assistant.ask(query)
            print(f"ğŸ’¬ åŠ©æ‰‹: {answer}")
        
        # æ˜¾ç¤ºå¯¹è¯æ‘˜è¦
        summary = assistant.get_conversation_summary()
        print(f"\nğŸ“‹ å¯¹è¯æ‘˜è¦: {json.dumps(summary, ensure_ascii=False, indent=2)}")
        
        print("\nâœ… æ™ºèƒ½åŠ©æ‰‹æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿:")
        print("1. è®¾ç½®äº†GEMINI_API_KEYç¯å¢ƒå˜é‡")
        print("2. å­˜åœ¨é¡¹ç›®æ•°æ®æ–‡ä»¶ output/projects_summary.json")
        print("3. å®‰è£…äº†å¿…è¦çš„ä¾èµ–åŒ…: google-generativeai jieba")