# 项目文件清理建议

## 可以安全删除的文件

### 1. 过时的爬虫版本
- `project_scraper.py` - 基础版爬虫（功能最基础，性能最差）
- `scraper_v2.py` - 早期版本（已被后续版本替代）

### 2. 相关的测试文件
- `test_enhanced_scraper.py` - 增强版测试（如果不再需要测试）
- `test_optimized.py` - 优化版测试（如果不再需要测试）

### 3. 过时的运行脚本
- `run_scraper.py` - 优化版运行脚本（建议使用增强版）

## 建议保留的文件

### 1. 核心增强版文件
- `project_scraper_enhanced.py` - 增强版爬虫（最新最完善）
- `run_scraper_enhanced.py` - 增强版运行脚本
- `digitaling_parser_enhanced.py` - 增强版解析器

### 2. 基础设施文件
- `driver_pool.py` - WebDriver连接池（增强版依赖）
- `config_optimized.py` - 配置文件（增强版使用）
- `config_loader.py` - 配置加载器
- `config.env` - 环境配置

### 3. 暂时保留的文件
- `project_scraper_optimized.py` - 优化版爬虫
  - 原因：`run_scraper.py`还在使用它
  - 建议：等确认不再需要后删除
- `digitaling_parser.py` - 优化版解析器
  - 原因：优化版爬虫依赖
  - 建议：等优化版删除后一起删除

### 4. 其他重要文件
- `web_server.py` - Web服务器
- `data_analyzer.py` - 数据分析器
- `project_assistant.py` - 项目助手
- `gemini_client.py` - Gemini客户端
- 各种启动脚本和配置文件

## 清理步骤

1. **备份重要数据**
   ```bash
   # 备份output目录
   cp -r output output_backup
   ```

2. **删除过时文件**
   ```bash
   rm project_scraper.py
   rm scraper_v2.py
   rm test_enhanced_scraper.py
   rm test_optimized.py
   ```

3. **更新文档**
   - 更新README文件，移除对已删除文件的引用
   - 更新启动脚本，确保指向正确的文件

4. **测试功能**
   - 运行增强版爬虫确保功能正常
   - 测试Web界面和数据分析功能

## 最终推荐的文件结构

```
网页爬虫/
├── project_scraper_enhanced.py      # 主爬虫（增强版）
├── run_scraper_enhanced.py         # 主运行脚本
├── digitaling_parser_enhanced.py    # 增强解析器
├── driver_pool.py                   # WebDriver连接池
├── config_optimized.py              # 配置文件
├── web_server.py                    # Web服务器
├── data_analyzer.py                 # 数据分析
├── project_assistant.py             # 项目助手
├── gemini_client.py                 # Gemini客户端
├── 启动系统.bat                     # 一键启动
├── 配置管理器.bat                   # 配置管理
└── README_*.md                      # 文档
```

## 注意事项

1. **删除前确认**：确保没有其他脚本依赖要删除的文件
2. **测试验证**：删除后要测试所有功能是否正常
3. **文档更新**：更新相关文档和说明
4. **版本控制**：如果使用Git，可以通过版本控制恢复误删的文件 